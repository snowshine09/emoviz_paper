@article{Tauch2016,
abstract = {The texts in mobile messages are not always easy to decipher since tone and body language is removed from the context. Emojis offer an attractive way to express emotions to avoid misunderstandings of message tone. In this paper we shed the light on the roles of Emojis in phone notification, we conducted an in-situ study to gather phone notification data. We outline the relationship between Emojis and various social network applications including WhatsApp, Facebook and Twitter. Early results allow us to draw several conclusions in relation to number, position, type and sentimental value of Emojis. It turns out that most popular Emojis in one social app is not as popular in the others. Emojis sentimental polarity in Twitter is high and overall number of Emojis is less than Facebook. The sentimental value of Emojis is more meaningful when there are multiple Emoji in one notification.},
author = {Tauch, Channary and Kanjo, Eiman},
doi = {10.1145/2968219.2968549},
file = {:Users/nasun/Dropbox/MyStuff/Academics/CSCL/SideProjects/emotiViz/papers/The roles of Emojis in Mobile Phone Notifications .pdf:pdf},
isbn = {978-1-4503-4462-3},
journal = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct},
keywords = {affective computing,emojis,pervasive computing,phone notifications,sentimental analysis},
pages = {1560--1565},
title = {{The Roles of Emojis in Mobile Phone Notifications}},
url = {http://doi.acm.org/10.1145/2968219.2968549},
year = {2016}
}
@article{Cramer2016,
abstract = {Emojis are an extremely common occurrence in mobile communications, but their meaning is open to interpretation. We investigate motivations for their usage in mobile messaging in the US. This study asked 228 participants for the last time that they used one or more emojis in a conversational message, and collected that message, along with a description of the emojis' intended meaning and function. We discuss functional distinctions between: adding additional emotional or situational meaning, adjusting tone, making a message more engaging to the recipient, conversation management, and relationship maintenance. We discuss lexical placement within messages, as well as social practices. We show that the social and linguistic function of emojis are complex and varied, and that supporting emojis can facilitate important conversational functions.},
author = {Cramer, Henriette and de Juan, Paloma and Tetreault, Joel},
doi = {10.1145/2935334.2935370},
file = {:Users/nasun/Dropbox/MyStuff/Academics/CSCL/SideProjects/emotiViz/papers/Sender-Intended Functions of Emojis in US Messaging.pdf:pdf},
isbn = {9781450344081},
journal = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services},
keywords = {emojis,messaging,mobile},
pages = {504--509},
title = {{Sender-intended Functions of Emojis in US Messaging}},
url = {http://dx.doi.org/10.1145/2935334.2935370},
year = {2016}
}
@article{Backstrom2014,
abstract = {A crucial task in the analysis of on-line social-networking systems is to identify important people --- those linked by strong social ties --- within an individual's network neighborhood. Here we investigate this question for a particular category of strong ties, those involving spouses or romantic partners. We organize our analysis around a basic question: given all the connections among a person's friends, can you recognize his or her romantic partner from the network structure alone? Using data from a large sample of Facebook users, we find that this task can be accomplished with high accuracy, but doing so requires the development of a new measure of tie strength that we term `dispersion' --- the extent to which two people's mutual friends are not themselves well-connected. The results offer methods for identifying types of structurally significant people in on-line applications, and suggest a potential expansion of existing theories of tie strength.},
archivePrefix = {arXiv},
arxivId = {1310.6753},
author = {Backstrom, Lars and Kleinberg, Jon},
doi = {10.1145/2531602.2531642},
eprint = {1310.6753},
file = {:Users/nasun/Dropbox/MyStuff/Academics/CSCL/SideProjects/emotiViz/papers/Romantic Partnerships and the Dispersion of Social Ties- A Network Analysis of Relationship Status on Facebook.pdf:pdf},
isbn = {9781450325400},
issn = {9781450325400},
journal = {Proceedings of the 17th ACM conference on Computer supported cooperative work {\&} social computing - CSCW '14},
keywords = {romantic relationships,social networks},
pages = {831--841},
title = {{Romantic partnerships and the dispersion of social ties}},
url = {http://arxiv.org/abs/1310.6753{\%}5Cnhttp://dl.acm.org/citation.cfm?doid=2531602.2531642},
year = {2014}
}
@article{ElAli2017,
author = {{El Ali}, Abdallah and Wallbaum, Torben and Wasmann, Merlin and Heuten, Wilko and Boll, Susanne C J},
doi = {10.1145/3027063.3053086},
file = {:Users/nasun/Dropbox/MyStuff/Academics/CSCL/SideProjects/emotiViz/papers/Face2Emoji- Using Facial Emotional Expressions to Filter Emojis.pdf:pdf},
isbn = {978-1-4503-4656-6},
journal = {Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
keywords = {crowdsourcing,emoji,emotion recognition,face2emoji,facial expression,input,keyboard,text entry},
pages = {1577--1584},
title = {{Face2Emoji: Using Facial Emotional Expressions to Filter Emojis}},
url = {http://doi.acm.org/10.1145/3027063.3053086},
year = {2017}
}
@article{Juwah2004,
abstract = {The SENLEF project is a resource for practioners wishing to improve their feedback practice or get some exciting new ideas. The project team have explored feedback issues with Higher Education Institutions (HEIs) across Scotland. From this we have collated case studies, devised a set of principles for good practice and developed a range of resources including a literature review, web links and workshop materials.},
author = {Juwah, Charles and Macfarlane-Dick, D and Matthew, Bob and Nicol, David and Ross, David and Smith, Brenda},
file = {:Users/nasun/Dropbox/MyStuff/Academics/CSCL/SideProjects/emotiViz/papers/Enhancing student learning through effective formative feedback.pdf:pdf},
isbn = {1904190588},
issn = {00411191},
journal = {Higher Education},
number = {68},
pages = {1--41},
pmid = {306003},
title = {{Enhancing student learning through effective formative feedback}},
url = {http://www.heacademy.ac.uk/resources/detail/resource{\_}database/id353{\_}effective{\_}formative{\_}feedback{\_}juwah{\_}etal},
volume = {June},
year = {2004}
}
@article{Jakobson,
author = {Jakobson, Roman},
journal = {Style in language},
pages = {350--377},
title = {{I960." Closing Statement: Linguistics and Poetics."}}
}
@article{Foong2017,
abstract = {... CHI 2017, May 06-11, 2017, Denver, CO, USA {\textcopyright} 2017 ACM. ISBN 978-1-4503-4655-9/17/05 {\$}15.00 DOI: http://dx.doi.org/ 10.1145 / 3025453.3025791 Figure 1. Five activities to consider when designing platforms that support online feedback exchange. Page 2. ... 
},
author = {Foong, Eureka and Dow, Steven P. and Bailey, Brian P. and Gerber, Elizabeth M.},
doi = {10.1145/3025453.3025791},
file = {:Users/nasun/Dropbox/MyStuff/Academics/CSCL/SideProjects/emotiViz/papers/Online Feedback Exchange- A Framework for Understanding the Socio-Psychological Factors.pdf:pdf},
isbn = {9781450346559},
journal = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems  - CHI '17},
pages = {4454--4467},
title = {{Online Feedback Exchange}},
url = {http://dl.acm.org/citation.cfm?doid=3025453.3025791},
year = {2017}
}
@article{Varlander2008,
abstract = {A growing, but still relatively small body of research underscores the importance of attending to students? experiences and emotions in higher education. One specific context in which emotions have a focal role is formal feedback situations. The aim of this paper is to provide a literature overview on the role of emotions, in sociology in general and learning in particular, and to draw on this literature in order to tentatively suggest how the role of students? emotions can increasingly be accounted for in the context of feedback situations. The claim of the paper is that emotions should not be considered as hindering learning. Rather, it underlines the focal role of emotions in learning as being a natural part of it. The paper suggests that learning activities such as ?feedback preparation activities? and ?feedback-on-the-feedback? can be helpful in order to acknowledge students? emotions in formal feedback situations. A growing, but still relatively small body of research underscores the importance of attending to students? experiences and emotions in higher education. One specific context in which emotions have a focal role is formal feedback situations. The aim of this paper is to provide a literature overview on the role of emotions, in sociology in general and learning in particular, and to draw on this literature in order to tentatively suggest how the role of students? emotions can increasingly be accounted for in the context of feedback situations. The claim of the paper is that emotions should not be considered as hindering learning. Rather, it underlines the focal role of emotions in learning as being a natural part of it. The paper suggests that learning activities such as ?feedback preparation activities? and ?feedback-on-the-feedback? can be helpful in order to acknowledge students? emotions in formal feedback situations.},
author = {V{\"{a}}rlander, Sara},
doi = {10.1080/13562510801923195},
file = {:Users/nasun/Dropbox/MyStuff/Academics/CSCL/SideProjects/emotiViz/papers/The role of students' emotions in formal feedback situation.pdf:pdf},
isbn = {1356251080},
issn = {1356-2517},
journal = {Teaching in Higher Education},
keywords = {feedback,learning,student emotion},
number = {2},
pages = {145--156},
title = {{The role of students' emotions in formal feedback situations}},
volume = {13},
year = {2008}
}
@article{Hao2014,
abstract = {In situations where there is a stressful workload or when unexpected things occur, people often find it difficult to regulate their emotions. To assist them in effective regulation, this design utilizes neurofeedback, providing users real-time emotion feedback to augment their emotional states through the use of a tangible interface. The visual feedback incorporates a series of colored LEDs that map an individual's affective state. This user study is structured to examine the effect of this training tool in a lab setting. The users are asked to watch several video clips to evoke an agitated state and then try to be calm by using this device. The results will be compared to the users ability to regulate their emotions without any visual tools. The longer term goal of this project is to develop a training tool, to teach people how to regulate their emotions more effectively in stressful situations. Author},
author = {Hao, Yu and Budd, James and Jackson, Melody Moore and Sati, Mukul and Soni, Sandeep},
doi = {10.1145/2559206.2581132},
file = {:Users/nasun/Dropbox/MyStuff/Academics/CSCL/SideProjects/emotiViz/papers/A Visual Feedback Design based   on a Brain-Computer Interface   to Assist Users Regulate   their Emotional State.pdf:pdf},
isbn = {9781450324748},
journal = {Proceedings of the extended abstracts of the 32nd annual ACM conference on Human factors in computing systems - CHI EA '14},
keywords = {Brain-Computer Interface,Emotion regulation,wearable product},
pages = {2491--2496},
title = {{A visual feedback design based on a brain-computer interface to assist users regulate their emotional state}},
url = {http://dl.acm.org/citation.cfm?doid=2559206.2581132},
year = {2014}
}
@article{Pohl2017,
abstract = {Emoji, a set of pictographic Unicode characters, have seen strong uptake over the last couple of years. All common mobile platforms and many desktop systems now support emoji entry and users have embraced their use. Yet, we currently know very little about what makes for good emoji entry. While soft keyboards for text entry are well optimized, based on language and touch models, no such information exists to guide the design of emoji keyboards. In this article, we investigate of the problem of emoji entry, starting with a study of the current state of the emoji keyboard implementation in Android. To enable moving forward to novel emoji keyboard designs, we then explore a model for emoji similarity that is able to inform such designs. This semantic model is based on data from 21 million collected tweets containing emoji. We compare this model against a solely description-based model of emoji in a crowdsourced study. Our model shows good performance in capturing detailed relationships between emoji.},
author = {Pohl, Henning and Domin, Christian and Rohs, Michael},
doi = {10.1145/3039685},
file = {:Users/nasun/Dropbox/MyStuff/Academics/CSCL/SideProjects/emotiViz/papers/Beyond Just Text- Semantic Emoji Similarity Modeling to Support Expressive Communication 👫📲😃.pdf:pdf},
issn = {10730516},
journal = {ACM Transactions on Computer-Human Interaction},
keywords = {emoji,emoticons,mobile text entry},
number = {1},
pages = {1--42},
title = {{Beyond Just Text: Semantic Emoji Similarity Modeling to Support Expressive Communication ???}},
url = {http://dl.acm.org/citation.cfm?doid=3040973.3039685},
volume = {24},
year = {2017}
}
@article{Leshed2007,
abstract = {Effective communication in project teams is important, but not often taught. We explore how feedback might improve teamwork in a controlled experiment where groups interact through chat rooms. Collaborators who receive high feedback ratings use different language than poor collaborators (e.g. more words, fewer assents, and less affect-laden language). Further, feedback affects language use. This suggests that a system could use linguistic analysis to automatically provide and visualize feedback to teach teamwork. To this end, we present GroupMeter, a system that applies principles discovered in the experiment to provide feedback both from peers and from automated linguistic analysis.},
author = {Leshed, Gilly and Hancock, Jeffrey T. and Cosley, Dan and McLeod, Poppy L. and Gay, Geri},
doi = {10.1145/1316624.1316655},
file = {:Users/nasun/Dropbox/MyStuff/Academics/CSCL/SideProjects/emotiViz/papers/Feedback for Guiding Reflection on Teamwork Practices .pdf:pdf},
isbn = {9781595938459},
journal = {Proceedings of the 2007 international ACM conference on Conference on supporting group work - GROUP '07},
keywords = {cscl,feedback,linguistic analysis,peer evaluation,teamwork},
pages = {217},
title = {{Feedback for guiding reflection on teamwork practices}},
url = {http://portal.acm.org/citation.cfm?doid=1316624.1316655},
year = {2007}
}
@article{Robb2015,
abstract = {The emotional reaction of an audience to a design can be difficult to assess but valuable to know. Moodsource allows intuitive visual communication between crowds and designers. A crowd responds to a design with selections from image banks. Visual summarization reduces the massed image choices down to a few representative images to be consumed at a glance by designer users. In two studies crowd users reported their ability to express emotions with the Moodsource image browsers and with text. Cognitive styles theories suggest users can be visual or verbal thinkers; crowd users preferring images thought they could express emotions equally well with abstract images as with text. Designer users "reading" the visual feedback reported that it represented the perceived mood from their designs and were inspired to make improvements.},
author = {Robb, David A and Padilla, Stefano and Kalkreuter, Britta and Chantler, Mike J},
doi = {10.1145/2685553.2702676},
file = {:Users/nasun/Dropbox/MyStuff/Academics/CSCL/SideProjects/emotiViz/papers/Moodsource- Enabling Perceptual and  Emotional Feedback from Crowds .pdf:pdf},
isbn = {978-1-4503-2946-0},
journal = {Proceedings of the 18th ACM Conference Companion on Computer Supported Cooperative Work {\&}{\#}38; Social Computing},
keywords = {abstract,crowdsourcing,image browsing interfaces,image summarization,perceptual and emotional imagery,visual design feedback},
pages = {21--24},
title = {{Moodsource: Enabling Perceptual and Emotional Feedback from Crowds}},
url = {http://doi.acm.org/10.1145/2685553.2702676},
year = {2015}
}
@article{Robb2017,
author = {Robb, David A and Padilla, Stefano and Methven, Thomas S and Kalkreuter, Britta and Chantler, Mike J},
file = {:Users/nasun/Dropbox/MyStuff/Academics/CSCL/SideProjects/emotiViz/papers/Image - based Emotion  Feedback- How Does the Crowd  Feel? And Why?.pdf:pdf},
isbn = {9781450349222},
pages = {451--463},
title = {{Image - based Emotion Feedback : How Does the Crowd Feel ? And Why ?}},
year = {2017}
}
@article{Robb2015a,
abstract = {Cognitive styles theories suggest that we divide into visual and verbal thinkers. In this paper we describe a method designed to encourage visual communication between designers and their audiences. This new visual feedback method is based on enabling fast intuitive selections by the crowd from image banks when responding to an idea. Visual summarization reduces the massed image choices to a small number of representative images. These summaries are then consumed at a glance by designers receiving the feedback leading to thoughtful reflection on their designs. We report an evaluation using two types of imagery for feedback. Twelve designers took part, receiving visual feedback in response to their designs. In semi-structured interviews they described their interpretation of the feedback, how it inspired them to change their designs and contrasted it with text feedback. Eleven of the twelve designers revealed that they would be enthusiastic users of a service providing this new mode of feedback.},
author = {Robb, David A and Padilla, Stefano and Kalkreuter, Britta and Chantler, Mike J},
doi = {10.1145/2702123.2702470},
file = {:Users/nasun/Dropbox/MyStuff/Academics/CSCL/SideProjects/emotiViz/papers/Crowdsourced Feedback With Imagery Rather Than Text-  Would Designers Use It? .pdf:pdf},
isbn = {9781450331456},
journal = {Proceedings of the ACM CHI'15 Conference on Human Factors in Computing Systems},
pages = {1355--1364},
title = {{Crowdsourced Feedback With Imagery Rather Than Text: Would Designers Use It?}},
url = {http://dx.doi.org/10.1145/2702123.2702470},
volume = {1},
year = {2015}
}
@article{Nogueira2014,
abstract = {Current approaches to game design improvements rely on gameplay testing, an iterative process following the test, try and fix pattern, relying on target audience feedback via standard questionnaires. Besides being a very time consuming phase, it is also highly subjective. In this paper, we demonstrate a generalizable approach for building predictive models of players' affective reactions across games and genres. Our aim is two-fold: 1) That game developers can use these models to more easily and accurately tune game parameters, allowing improved gaming experiences, and 2) That these models can be used as the basis for parameterisable and adaptive affective gaming. This paper describes our preliminary results regarding a novel, physiological-based method for emotional player profiling, which consists on the following three phases: (i) monitoring players' emotional states and game events, (ii) identifying player's emotional reactions to game events and (iii) individual and cluster-based modelling of players emotional reactions.},
author = {Nogueira, Pedro A. and Aguiar, R??ben and Rodrigues, Rui and Oliveira, Eug??nio},
doi = {10.1109/CISTI.2014.6877079},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Nogueira et al. - 2014 - Designing players' emotional reaction models A generic method towards adaptive affective gaming.pdf:pdf},
isbn = {9789899843431},
issn = {21660735},
journal = {Iberian Conference on Information Systems and Technologies, CISTI},
keywords = {Affective Gaming,Biofeedback,Digital Games,Game Design,Gameplay Testing,Player Experience,Player Models},
title = {{Designing players' emotional reaction models: A generic method towards adaptive affective gaming}},
year = {2014}
}
@article{Ng2015,
abstract = {In recent years, there have been increasing interests in the field of Human Computer Interaction (HCI) towards gaming. Due to the competitive industry and high demand for novelty in today's world, gaming has now become a valuable and stimulating research setting for HCI researchers to study its interface and interaction design, input devices, graphical user interface, social communication and development processes. Video games have advanced technologically and visually, and seem to demand greater levels of engagement from their users. The degree of interaction designed into a game is vital to effectively generate a constructive or destructive player (user) experience. The success of the gaming industry has bred a desire to accurately understand and measure player responses to video gaming, thus making video games a perfect test-bed for HCI explorations. This paper will attempt to address and review the literature on affective user-centered design principles, elements and methodologies that are applicable in video games.},
author = {Ng, Yiing Y Ng and Khong, Chee Weng},
doi = {10.1109/IUSER.2014.7002681},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Ng, Khong - 2015 - A review of affective user-centered design for video games.pdf:pdf},
isbn = {9781479958122},
issn = {18770428},
journal = {Proceedings - 2014 3rd International Conference on User Science and Engineering: Experience. Engineer. Engage, i-USEr 2014},
keywords = {affective design,affective gaming,user-centered design,video games},
pages = {79--84},
title = {{A review of affective user-centered design for video games}},
year = {2015}
}
@article{Szegletes2012,
abstract = {Over the past decades, reinforcement learning has been applied in several fields of computer science (especially in machine learning) as a learning algorithm. The same model can be used in cognitive neuroscience. In this case, neurotransmitters are providing the rewarding signal, and therefore in the background a similar learning process occurs as in reinforcement learning. According to previous studies, the same chemicals are produced through playing video games. In this paper, we aim to show a few methods and promising approaches to advance a biofeedback-controlled self-rewarding learning framework, which can be established in numerous applications. In recent times, mobile devices (phones and tablets as well) acquire more and more popularity among teenagers. Our objective is to develop a framework on these devices to measure and interpret neural activity and learning progress in general, so a related system can be developed to sustain attention and as a result, adaptive computer games may be developed in the near future.},
author = {Szegletes, Luca and Forstner, Bertalan},
doi = {10.1109/CogInfoCom.2012.6421998},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Szegletes, Forstner - 2012 - Towards biofeedback-controlled self-rewarding learning with mobile devices.pdf:pdf},
isbn = {9781467351874},
journal = {3rd IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2012 - Proceedings},
keywords = {adaptive games,affective games,biofeedback,mobile devices,reinforcement learning},
pages = {303--308},
title = {{Towards biofeedback-controlled self-rewarding learning with mobile devices}},
year = {2012}
}
@article{Nogueira2014a,
abstract = {Emotionally adaptive games are one of the holy grails of modern affective game research. However, current state of the art affective games rely on static game adaptation mechanics that assume a fixed emotional reaction from players every time. Not only this, most commercial titles have no affective adaptation loop whatsoever and their design is based on game design optimizations via typical beta-testing procedures, which falls short of ideal both in the level design and long-term game play experience fronts. In this paper, we demonstrate a generalizable approach for building predictive models of players' emotional reactions across different games and game genres. We describe a physiological approach for modelling players' emotional reactions, which relies on features extracted from players' emotional responses to game events, which were collected and extrapolated through their physiological data during actual game play sessions. Based on the optimal feature sets found by three feature selection algorithms (best first, sequential feature selection and genetic search), the collected features are used to create computational models of players' emotional reactions on the arousal and valence dimensions of emotion, using several machine learning algorithms. We expect this approach will allow both a more objective and quicker prototyping for digital games, as well as foster a future generation of affective games capable of modelling players' affective profiles over time, thus adapting to their changing preferences and needs. {\textcopyright} 2014 IEEE.},
author = {Nogueira, Pedro A. and Aguiar, R{\'{u}}ben and Rodrigues, Rui and Oliveira, Eugenio},
doi = {10.1109/WI-IAT.2014.178},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Nogueira et al. - 2014 - Computational models of players' physiological-based emotional reactions A digital games case study.pdf:pdf},
isbn = {9781479941438},
journal = {Proceedings - 2014 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology - Workshops, WI-IAT 2014},
keywords = {- player experience,affective gaming,biofeedback,capable of adapting themselves,digital games,emotional states in order,game design,gameplay testing,in response to players,player models,target affective,to elicit a certain},
pages = {641--661},
title = {{Computational models of players' physiological-based emotional reactions: A digital games case study}},
volume = {3},
year = {2014}
}
@article{Vachiratamporn2014,
abstract = {In this research, we investigated two important aspects of affective gaming, which are the recognition of the player's affective states and the adaptation of the game based on the player's current affective state, by using survival horror games as an experimental environment. In the previous work, we analyzed the affective states of players collected through our own affect annotation tool during their gameplay and constructed affective-state prediction models that predicted their affective states from their brainwave and heart rate signals collected concurrently. In this work, we developed an affective survival horror game based on the previous findings and conducted another experiment to compare between affective and non-affective versions of the game. In the affective version, the timing of horror events were implicitly changed based on the player's affective state. The result showed that the implicit change of timing made no significant difference in the evaluation of the players, but the game itself shows good potential for future research in the affective gaming field.},
author = {Vachiratamporn, Vanus and Moriyama, Koichi and Fukui, Ken Ichi and Numao, Masayuki},
doi = {10.1109/CIG.2014.6932893},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Vachiratamporn et al. - 2014 - An implementation of affective adaptation in survival horror games.pdf:pdf},
isbn = {9781479935468},
issn = {23254289},
journal = {IEEE Conference on Computatonal Intelligence and Games, CIG},
number = {i},
title = {{An implementation of affective adaptation in survival horror games}},
year = {2014}
}
@article{Novak2014,
abstract = {In an affective feedback loop, the computer maps various measurements to affective variables such as enjoyment, then adapts its behavior based on the recognized affects. The affect recognition is never perfect, and its accuracy (percentage of times the correct affective state is recognized) depends on many factors. However, it is unclear how this accuracy relates to the overall user experience. As recognition accuracy is difficult to control in a real affective feedback loop, we describe a method of simulating recognition accuracy in a game where difficulty is increased or decreased after each round. The game was played by 261 participants at different simulated recognition accuracies. Participants reported their satisfaction with the recognition algorithm as well as their overall game experience. We observed that in such a game, the affective feedback loop must adapt game difficulty with an accuracy of at least 80 percent to be accepted by users. Furthermore, users who do not enjoy the game are likely to stop playing it rather than continue playing and report low enjoyment. However, the acceptable recognition accuracy may not generalize to other contexts, and studies of affect recognition accuracies in other applications are needed.},
author = {Novak, Domen and Nagle, Aniket and Riener, Robert},
doi = {10.1109/TAFFC.2014.2326870},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Novak, Nagle, Riener - 2014 - Linking recognition accuracy and user experience in an affective feedback loop.pdf:pdf},
isbn = {1949-3045},
issn = {19493045},
journal = {IEEE Transactions on Affective Computing},
keywords = {Affective computing,computer games,machine learning,physiological computing,user acceptance},
number = {2},
pages = {168--172},
title = {{Linking recognition accuracy and user experience in an affective feedback loop}},
volume = {5},
year = {2014}
}
@article{Kotsia2012,
abstract = {Affective, 'emotional' as widely known, gaming, constitutes the new frontier for game design and development. The ultimate goal is being able to read the emotional state of a gamer and use it to change the game in such a way so as to provide to him/her a more immersive experience, a better gameplay. However, existing affective gaming approaches use specialized sensors in order to extract behavioral cues, introducing in that way a variety of challenges. The main issue to be resolved is that of affecting the player's immersion in the game scenario by having an impact on his/her behavior, in terms of the actions and emotions he/she displays. In this paper we survey existing approaches in the field of affective gaming, briefly describing the sensors used to extract behavioral cues (mainly physiological ones) and also presenting the commercial applications developed that employ those sensors. In addition, we propose two effective, low-cost and easy to implement affective game scenarios, in which the behavior of a social group playing with a games machine is studied. The proposed scenarios `use' Kinect to extract the behavioral cues under examination, that can be later used to evoke specific emotions to the players and alter the game's objective and plot, providing in that way a more realistic interaction between the player and the game.},
author = {Kotsia, Irene and Patras, Ioannis and Fotopoulos, Spiros},
doi = {10.1109/ISCCSP.2012.6217768},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Kotsia, Patras, Fotopoulos - 2012 - Affective gaming Beyond using sensors(2).pdf:pdf},
isbn = {9781467302760},
journal = {5th International Symposium on Communications Control and Signal Processing, ISCCSP 2012},
keywords = {Affective gaming,action recognition,emotion recognition,group behavior,group interactions,group relationships},
number = {May},
pages = {2--4},
title = {{Affective gaming: Beyond using sensors}},
year = {2012}
}
@article{Argyriou2013,
abstract = {A typical gaming scenario, as developed in the past 20 years, involves a player interacting with a game using a specialized input device, such as a joystic, a mouse, a keyboard, etc. Recent technological advances and new sensors (for example, low cost commodity depth cameras) have enabled the introduction of more elaborated approaches in which the player is now able to interact with the game using his body pose, facial expressions, actions, and even his physiological signals. A new era of games has already started, employing computer vision techniques, brain-computer interfaces systems, haptic and wearable devices. The future lies in games that will be intelligent enough not only to extract the player's commands provided by his speech and gestures but also his behavioral cues, as well as his/her emotional states, and adjust their game plot accordingly in order to ensure more realistic and satisfactory gameplay experience. This special issue on modern control for computer games discusses several interdisciplinary factors that influence a user's input to a game, something directly linked to the gaming experience. These include, but are not limited to, the following: behavioral affective gaming, user satisfaction and perception, motion capture and scene modeling, and complete software frameworks that address several challenges risen in such scenarios.},
author = {Argyriou, Vasileios and Kotsia, Irene and Zafeiriou, Stefanos and Petrou, Maria},
doi = {10.1109/TCYB.2013.2283551},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Argyriou et al. - 2013 - Guest editorial introduction to the special issue on modern control for computer games.pdf:pdf},
issn = {21682267},
journal = {IEEE Transactions on Cybernetics},
number = {6},
pages = {1516--1518},
pmid = {24235260},
title = {{Guest editorial introduction to the special issue on modern control for computer games}},
volume = {43},
year = {2013}
}
@article{Kotsia2013,
abstract = {A typical gaming scenario involves a player interacting with a game by a specialized input device, such as a joystic, a mouse, a keyboard etc. Recent technological advances have enabled the introduction of more elaborated approaches in which the player is able to interact with the game using his/her body pose, facial expressions, actions, even his physiological signals (heart beat rate, encephalogram, skin conductivity etc). The future lies in 'affective gaming', that is games that will be 'intelligent' enough not only to extract the player's commands by his speech and gestures but also by his behavioral cues, and his/her emotional states and adjust their game plot accordingly, in order to ensure more realistic and satisfactory gameplay experience. In this paper, we review the area of affective gaming by describing existing approaches and discussing recent technological advances. We elaborate on different sources of affect information and summarize the existing commercial affective gaming applications. We proceed with outlining some of the most important problems that have to be tackled in order to create more realistic and efficient interactions between players and games and conclude by high-lighting the challenges such systems must overcome. {\textcopyright} 2013 IEEE.},
author = {Kotsia, Irene and Zafeiriou, Stefanos and Fotopoulos, Spiros},
doi = {10.1109/CVPRW.2013.100},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Kotsia, Zafeiriou, Fotopoulos - 2013 - Affective gaming A comprehensive survey.pdf:pdf},
isbn = {9780769549903},
issn = {21607508},
journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
keywords = {affective gaming},
pages = {663--670},
title = {{Affective gaming: A comprehensive survey}},
year = {2013}
}
@article{Shaker2013,
abstract = {Estimating affective and cognitive states in conditions of rich human-computer interaction, such as in games, is a field of growing academic and commercial interest. Entertainment and serious games can benefit from recent advances in the field as, having access to predictors of the current state of the player (or learner) can provide useful information for feeding adaptation mechanisms that aim to maximize engagement or learning effects. In this paper, we introduce a large data corpus derived from 58 participants that play the popular Super Mario Bros platform game and attempt to create accurate models of player experience for this game genre. Within the view of the current research, features extracted both from player gameplay behavior and game levels, and player visual characteristics have been used as potential indicators of reported affect expressed as pairwise preferences between different game sessions. Using neuroevolutionary preference learning and automatic feature selection, highly accurate models of reported engagement, frustration, and challenge are constructed (model accuracies reach 91{\%}, 92{\%}, and 88{\%} for engagement, frustration, and challenge, respectively). As a step further, the derived player experience models can be used to personalize the game level to desired levels of engagement, frustration, and challenge as game content is mapped to player experience through the behavioral and expressivity patterns of each player.},
author = {Shaker, Noor and Asteriadis, Stylianos and Yannakakis, Georgios N. and Karpouzis, Kostas},
doi = {10.1109/TCYB.2013.2271738},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Shaker et al. - 2013 - Fusing visual and behavioral cues for modeling user experience in games.pdf:pdf},
isbn = {2168-2267},
issn = {21682267},
journal = {IEEE Transactions on Cybernetics},
keywords = {Content personalization,Experience-driven procedural content generation,Multimodal interaction,Player experience modeling,Visual cues},
number = {6},
pages = {1519--1531},
pmid = {24273140},
title = {{Fusing visual and behavioral cues for modeling user experience in games}},
volume = {43},
year = {2013}
}
@article{Wilkinson2013,
abstract = {Emotions play an important role in cognition, memory, attention and motivation but the current generation of educational games largely ignore emotions' role in learning. However, there is a movement within games development for entertainment to create more affective gameplay. As such this paper will discuss how new research from affective neuroscience, affective computing and contemporary psychological learning theories can inform educational game development. Firstly outlining our current understanding of emotions in learning, this paper will then explore three key aspects of affective game design: sensing and recognition of emotions; modelling emotions and emotion expression by game characters and player avatars. In this section it will review currently available technology, theories and models as appropriate. Finally this paper will explain how incorporating these aspects in educational game design can produce more effectual learning experiences by being aware of affective game design principles that effect attention, memory and motivation. Although this paper is not conclusive, it is comprehensive enough to bridge the gap between academia and industry, so that commercial educational games development can benefit from our current understanding of affective game design and emotions role in attention, memory and motivation.},
author = {Wilkinson, Phillip},
doi = {10.1109/VS-GAMES.2013.6624219},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Wilkinson - 2013 - Affective educational games Utilizing emotions in game-based learning.pdf:pdf},
isbn = {9781479909650},
journal = {2013 5th International Conference on Games and Virtual Worlds for Serious Applications, VS-GAMES 2013},
keywords = {Affective gaming,affective computing,attention,educational games,games-based learning,learning,memory,motivation},
title = {{Affective educational games: Utilizing emotions in game-based learning}},
year = {2013}
}
@article{P??rezMart??nez2009,
abstract = {Information about interactive virtual environments, such as games, is perceived by users through a virtual camera. While most interactive applications let the users control the camera, in complex navigation tasks within 3D environments users often get frustrated with the interaction. In this paper, we motivate for the inclusion of camera control as a vital component of affective adaptive interaction in games and investigate the impact of camera viewpoints on psy-chophysiology of players through an evaluation game survey experiment. The statistical analysis presented demonstrates that emotional responses and physiological indexes are affected by camera settings.},
author = {{P??rez Mart??nez}, H??ctor and Jhala, Arnav and Yannakakis, Georgios N.},
doi = {10.1109/ACII.2009.5349592},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Prez Martnez, Jhala, Yannakakis - 2009 - Analyzing the impact of camera viewpoint on player psychophysiology.pdf:pdf},
isbn = {9781424447992},
journal = {Proceedings - 2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops, ACII 2009},
title = {{Analyzing the impact of camera viewpoint on player psychophysiology}},
year = {2009}
}
@article{Franklin2014,
author = {Franklin, Stan and Madl, Tamas and D'Mello, Sidney and Snaider, Javier},
doi = {10.1109/TAMD.2013.2277589},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Franklin et al. - 2014 - LIDA A Systems-level Architecture for Cognition, Emotion, and Learning.pdf:pdf},
isbn = {1943-0604 VO - 6},
issn = {1943-0604},
journal = {IEEE Transactions on Autonomous Mental Development},
number = {1},
pages = {19--41},
title = {{LIDA: A Systems-level Architecture for Cognition, Emotion, and Learning}},
url = {http://ieeexplore.ieee.org/document/6587077/},
volume = {6},
year = {2014}
}
@article{Popescu2014,
abstract = {In this paper we present GAMYGDALA, an emotional appraisal engine that enables game developers to easily add emotions to their Non-Player Characters (NPC). Our approach proposes a solution that is positioned between event coding of affect, where individual events have predetermined annotated emotional consequences for NPCs, and a full blown cognitive appraisal model. Instead, for an NPC that needs emotions the game developer defines goals and annotates game events with a relation to these goals. Based on this input, GAMYGDALA produces an emotion for that NPC according to the well-known OCC model. In this paper we provide evidence for the following: GAMYGDALA provides black-box Game-AI independent emotion support, is efficient for large numbers of NPCs, and is psychologically grounded.},
author = {Popescu, Alexandru and Broekens, Joost and {Van Someren}, Maarten},
doi = {10.1109/T-AFFC.2013.24},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Popescu, Broekens, Van Someren - 2014 - GAMYGDALA An emotion engine for games.pdf:pdf},
isbn = {1949-3045 VO - 5},
issn = {19493045},
journal = {IEEE Transactions on Affective Computing},
keywords = {Affective computing,Computer games,Psychological model},
number = {1},
pages = {32--44},
title = {{GAMYGDALA: An emotion engine for games}},
volume = {5},
year = {2014}
}
@article{Wu2010,
abstract = {A closed-loop system that offers real-time assessment and manipulation of a user's affective and cognitive states is very useful in developing adaptive environments which respond in a rational and strategic fashion to real-time changes in user affect, cognition, and motivation. The goal is to progress the user from suboptimal cognitive and affective states toward an optimal state that enhances user performance. In order to achieve this, there is need for assessment of both 1) the optimal affective/cognitive state and 2) the observed user state. This paper presents approaches for assessing these two states. Arousal, an important dimension of affect, is focused upon because of its close relation to a user's cognitive performance, as indicated by the Yerkes-Dodson Law. Herein, we make use of a Virtual Reality Stroop Task (VRST) from the Virtual Reality Cognitive Performance Assessment Test (VRCPAT) to identify the optimal arousal level that can serve as the affective/cognitive state goal. Three stimuli presentations (with distinct arousal levels) in the VRST are selected. We demonstrate that when reaction time is used as the performance measure, one of the three stimuli presentations can elicit the optimal level of arousal for most subjects. Further, results suggest that high classification rates can be achieved when a support vector machine is used to classify the psychophysiological responses (skin conductance level, respiration, ECG, and EEG) in these three stimuli presentations into three arousal levels. This research reflects progress toward the implementation of a closed-loop affective computing system.},
author = {Wu, Dongrui and Courtney, Christopher G. and Lance, Brent J. and Narayanan, Shrikanth S. and Dawson, Michael E. and Oie, Kelvin S. and Parsons, Thomas D.},
doi = {10.1109/T-AFFC.2010.12},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Wu et al. - 2010 - Optimal arousal identification and classification for affective computing using physiological signals Virtual reality.pdf:pdf},
isbn = {19493045},
issn = {19493045},
journal = {IEEE Transactions on Affective Computing},
keywords = {Affective computing,Stroop task,Yerkes-Dodson Law,affect recognition,arousal classification,virtual reality},
number = {2},
pages = {109--118},
title = {{Optimal arousal identification and classification for affective computing using physiological signals: Virtual reality stroop task}},
volume = {1},
year = {2010}
}
@article{Chanel2011,
author = {Chanel, Guillaume and Rebetez, Cyril and B{\'{e}}trancourt, Mireille and Pun, Thierry},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Chanel et al. - 2011 - for Adaptation of Game Difficulty.pdf:pdf},
number = {6},
pages = {1052--1063},
title = {{for Adaptation of Game Difficulty}},
volume = {41},
year = {2011}
}
@article{Ekanayake2010,
abstract = {There is an increasing interest to use computer games for non-traditional education, such as for training purposes. For training education, simulators are considered as offering more realistic learning environments to experience situations that are similar to real world. This type of learning is more beneficial for practicing critical situations which are difficult or impossible in real world training, for instance experience the consequences of unsafe driving. However, the effectiveness of simulation-based learning of this nature is dependent upon the learner's engagement and explorative behaviour. Most current learner evaluation systems are unable to capture this type of learning. Therefore, in this paper we introduce the concept of game interaction state graphs (GISGs) to capture the engagement in explorative and experience-based training tasks. These graphs are constructed based on rules which capture psychologically significant learner behaviours and situations. Simple variables reflecting game state and learner's controller actions provide the ingredients to the rules. This approach eliminates the complexity involved with other similar approaches, such as constructing a full-fledged cognitive model for the learner. GISGs, at minimum, can be used to evaluate the explorative behaviour, the training performance and personal preferences of a learner.},
author = {Ekanayake, Hiran and Backlund, Per and Ziemke, Tom and Ramberg, Robert and Hewagamage, Kamalanath},
doi = {10.1109/ICTER.2010.5643272},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Ekanayake et al. - 2010 - Game interaction state graphs for evaluation of user engagement in explorative and experience-based training g.pdf:pdf},
isbn = {9781424490417},
journal = {2010 International Conference on Advances in ICT for Emerging Regions, ICTer 2010},
keywords = {Driving simulator training,Engagement,Experience-based systems,Game interaction,Serious games},
pages = {40--44},
title = {{Game interaction state graphs for evaluation of user engagement in explorative and experience-based training games}},
year = {2010}
}
@article{Pantic2003,
abstract = {The ability to recognize affective states of a person we are communicating with is the core of emotional intelligence. Emotional intelligence is afacet of human intelligence that has been argued to be indispensable and perhaps the most important for successful inter- personal social interaction. This paper argues that next-generation human–computer interaction (HCI) designs need to include the essence of emotional intelligence—the ability to recognize a user's affective states—in order to become more human-like, more effective, and more efficient. Affective arousal modulates all nonverbal communicative cues (facial expressions, bodymovements, and vocal and physiological reactions). In a face-to-face interaction, humans detect and interpret those interactive signals of their communicator with little or no effort. Yet design and development of an automated system that accomplishes these tasks is rather difficult. This paper surveys the past work in solving these problems by a computer and provides a set of recommendations for developing the first part of an intelligent multimodal HCI—an automatic personalized analyzer of a user's nonverbal affective feedback. Keywords—Affective},
author = {Pantic, Maja and Rothkrantz, Leon J M},
doi = {10.1109/JPROC.2003.817122},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Pantic, Rothkrantz - 2003 - Toward an affect-sensitive multimodal human-computer interaction.pdf:pdf},
isbn = {0018-9219},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {Affective computing,Affective states,Automatic analysis of nonverbal communicative cues,Human-computer interaction (HCI),Multimodal human-computer interaction,Personalized human-computer interaction},
number = {9},
pages = {1370--1390},
title = {{Toward an affect-sensitive multimodal human-computer interaction}},
volume = {91},
year = {2003}
}
@article{McDuff2012,
abstract = {We present AffectAura, an emotional prosthetic that allows users to reflect on their emotional states over long periods of time. We designed a multimodal sensor set-up for conti- nuous logging of audio, visual, physiological and contex- tual data, a classification scheme for predicting user affec- tive state and an interface for user reflection. The system continuously predicts a user's valence, arousal and engage- ment, and correlates this with information on events, com- munications and data interactions. We evaluate the interface through a user study consisting of six users and over 240 hours of data, and demonstrate the utility of such a reflec- tion tool. We show that users could reason forward and backward in time about their emotional experiences using the interface, and found this useful.},
author = {McDuff, Daniel and Karlson, Amy and Kapoor, Ashish and Roseway, Asta and Czerwinski, Mary},
doi = {10.1145/2207676.2208525},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/McDuff et al. - 2012 - AffectAura An Intelligent System for Emotional Memory.pdf:pdf},
isbn = {9781450310154},
issn = {9781450310154},
journal = {Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems - CHI '12},
keywords = {affect,machine learning,visualization},
pages = {849},
title = {{AffectAura: An Intelligent System for Emotional Memory}},
url = {http://dl.acm.org/citation.cfm?doid=2207676.2208525{\%}0Ahttp://dl.acm.org/citation.cfm?id=2207676.2208525},
year = {2012}
}
@article{Molinari2016,
abstract = {Emotions play a crucial role in collaboration. They help to make inferences about the partner and can strongly influence task performance. Due to limitations of emotional cues in computer-mediated collaboration (CMC), the collaborative process can be impacted. In this study, we report on the effect of an Emotion Awareness Tool (EAT) designed to facilitate the sharing of emotions between partners, on the perceived emotions after collaboration and the perceived quality of the interaction. Results showed that the EAT stimulated participants to engage in a mutual modeling of emotions. In the EAT condition, the perceived amount of time spent on emotion modeling process was positively correlated to the perceived intensity of positive emotions after collaboration. The EAT increased the perceived degree of transactivity, but only for women. This study provides a first step in exploring the effect of emotion awareness in CMC tasks including a comparing approach for its gender-specific relevance. {\textcopyright} ISLS.},
author = {Molinari, G and Chanel, G and B{\'{e}}trancourt, M and Pun, T and Bozelle, C},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Molinari et al. - 2016 - Emotion feedback during computer-mediated collaboration Effects on self-reported emotions and perceived interac.pdf:pdf},
isbn = {15734552 (ISSN)},
issn = {15734552},
journal = {Computer-Supported Collaborative Learning Conference, CSCL},
keywords = {Awareness tool,Behavioral research,Collaborative process,Computer science,Emotion modeling,Perceived quality,Positive emotions,Task performance,Time spent},
number = {2009},
pages = {336--343},
title = {{Emotion feedback during computer-mediated collaboration: Effects on self-reported emotions and perceived interaction}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84886502061{\&}partnerID=40{\&}md5=d97d49119837695d415c2e8cfb3a1a6c},
volume = {1},
year = {2016}
}
@article{Miller2016,
abstract = {Emoji are commonly used in modern text communication. However, as graphics with nuanced details, emoji may be open to interpretation. Emoji also render differently on different viewing platforms (e.g., Apple's iPhone vs. Google's Nexus phone), potentially leading to communication errors. We explore whether emoji renderings or differences across platforms give rise to diverse interpretations of emoji. Through an online survey, we solicit people's interpretations of a sample of the most popular emoji characters, each rendered for multiple platforms. Both in terms of sentiment and semantics, we analyze the variance in interpretation of the emoji, quantifying which emoji are most (and least) likely to be misinterpreted. In cases in which participants rated the same emoji rendering, they disagreed on whether the sentiment was positive, neutral, or negative 25{\%} of the time. When considering renderings across platforms, these disagreements only increase. Overall, we find significant potential for miscommunication, both for individual emoji renderings and for different emoji renderings across platforms.},
author = {Miller, Hannah and Thebault-Spieker, Jacob and Chang, Shuo and Johnson, Isaac and Terveen, Loren and Hecht, Brent},
doi = {10.1089/cyber.2011.0179},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Miller et al. - 2016 - “Blissfully happy” or “ready to fight” Varying Interpretations of Emoji(3).pdf:pdf},
isbn = {9781577357582},
issn = {2152-2715},
journal = {Association for the Advancement of Artificial Intelligence},
pages = {259--268},
title = {{“Blissfully happy” or “ready to fight”: Varying Interpretations of Emoji}},
url = {http://www.aaai.org/ocs/index.php/ICWSM/ICWSM16/paper/view/13167},
year = {2016}
}
@article{Wilson2017,
author = {Wilson, Graham and Brewster, Stephen A},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Wilson, Brewster - 2017 - Multi-Moji Combining Thermal , Vibrotactile {\&} Visual Stimuli to Expand the Affective Range of Feedback.pdf:pdf},
isbn = {9781450346559},
pages = {3025614},
title = {{Multi-Moji : Combining Thermal , Vibrotactile {\&} Visual Stimuli to Expand the Affective Range of Feedback}},
year = {2017}
}
@article{Novak2015,
abstract = {There is a new generation of emoticons, called emojis, that is increasingly being used in mobile communications and social media. In the past two years, over ten billion emojis were used on Twitter. Emojis are Unicode graphic symbols, used as a shorthand to express concepts and ideas. In contrast to the small number of well-known emoticons that carry clear emotional contents, there are hundreds of emojis. But what are their emotional contents? We provide the first emoji sentiment lexicon, called the Emoji Sentiment Ranking, and draw a sentiment map of the 751 most frequently used emojis. The sentiment of the emojis is computed from the sentiment of the tweets in which they occur. We engaged 83 human annotators to label over 1.6 million tweets in 13 European languages by the sentiment polarity (negative, neutral, or positive). About 4{\%} of the annotated tweets contain emojis. The sentiment analysis of the emojis allows us to draw several interesting conclusions. It turns out that most of the emojis are positive, especially the most popular ones. The sentiment distribution of the tweets with and without emojis is significantly different. The inter-annotator agreement on the tweets with emojis is higher. Emojis tend to occur at the end of the tweets, and their sentiment polarity increases with the distance. We observe no significant differences in the emoji rankings between the 13 languages and the Emoji Sentiment Ranking. Consequently, we propose our Emoji Sentiment Ranking as a European language-independent resource for automated sentiment analysis. Finally, the paper provides a formalization of sentiment and a novel visualization in the form of a sentiment bar.},
archivePrefix = {arXiv},
arxivId = {1509.07761},
author = {Novak, Petra Kralj and Smailovi??, Jasmina and Sluban, Borut and Mozeti??, Igor},
doi = {10.1371/journal.pone.0144296},
eprint = {1509.07761},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Novak et al. - 2015 - Sentiment of emojis.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {12},
pages = {1--22},
pmid = {26641093},
title = {{Sentiment of emojis}},
volume = {10},
year = {2015}
}
@article{Hentschel2017,
author = {Hentschel, Jasmine},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Hentschel - 2017 - Goodbye Text , Hello Emoji Mobile Communication on WeChat in China.pdf:pdf},
isbn = {9781450346559},
pages = {748--759},
title = {{Goodbye Text , Hello Emoji : Mobile Communication on WeChat in China}},
year = {2017}
}
@article{Lajoie2008,
abstract = {This commentary reviews the distinctions researchers make in defining metacognition, self-regulation, and self-regulated learning along with the methods used to explore these constructs. Bandura's notion of reciprocal determinism (1977) is revisited in the context of situated learning, whereby interactions between the person, behavior, and environment take on new meaning when examining learning and affect in specific contexts where knowledge is constructed through interacting with all that the environment affords, be that material or human. The interaction between the mind and environment continues to be an interesting question with regard to these three constructs, and this interaction can be explored by using computers as cognitive tools. Technology-rich environments are described that provide opportunities for assessing and validating metacognition, self-regulation, and self-regulated learning with future directions for assessing co-regulation of teams of learners. Many reputable scholars in our field have discussed how theories evolve either through evolutionary or revolutionary methods where the fittest theories, concepts, and constructs predominate the literature and guide research for several years and decades (Kuhn 1996; Mayer 1997). Theory change can be seamless such as a natural progression where old ideas die when they have outlived their usefulness and new ones thrive. On the other hand, theory change can become a battle of words that polarizes our field into different camps. Theory change based on empirical findings and constructive dialogue is healthy. The research presented in this special issue on metacognition, self-regulation (SR), and self-regulated learning (SRL) is unique because it serves to move the field forward without alienating those who have been working within a paradigm with one set of assumptions for several years. The contributors to this journal outline the distinctions between these three constructs and highlight where the edges are blurred. Most importantly, they seek ways to improve our},
archivePrefix = {arXiv},
arxivId = {arXiv:1002.2562v1},
author = {Lajoie, Susanne P.},
doi = {10.1007/s10648-008-9088-1},
eprint = {arXiv:1002.2562v1},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Lajoie - 2008 - Metacognition, self regulation, and self-regulated learning A rose by any other name.pdf:pdf},
isbn = {1064800890},
issn = {1040726X},
journal = {Educational Psychology Review},
keywords = {Computer based learning environments,Metacogniton,Self-regulated learning,Self-regulation},
number = {4},
pages = {469--475},
pmid = {35077625},
title = {{Metacognition, self regulation, and self-regulated learning: A rose by any other name?}},
volume = {20},
year = {2008}
}
@article{Gross2015,
abstract = {One of the fastest growing areas within psychology is the field of emotion regulation. However, enthusiasm for this topic continues to outstrip conceptual clarity, and there remains considerable uncertainty as to what is even meant by " emotion regulation. " The goal of this review is to examine the current status and future prospects of this rapidly growing field. In the first section, I define emotion and emotion regulation and distinguish both from related constructs. In the second section, I use the process model of emotion regulation to selectively review evidence that different regulation strategies have different consequences. In the third section, I introduce the extended process model of emotion regulation; this model considers emotion regulation to be one type of valuation, and distinguishes three emotion regulation stages (identification, selection, implementation). In the final section, I consider five key growth points for the field of emotion regulation.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Gross, James J.},
doi = {10.1080/1047840X.2014.940781},
eprint = {arXiv:1011.1669v3},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Gross - 2015 - Emotion Regulation Current Status and Future Prospects.pdf:pdf},
isbn = {1532-7965(Electronic);1047-840X(Print)},
issn = {1047-840X},
journal = {Psychological Inquiry},
number = {1},
pages = {1--26},
pmid = {15991970},
title = {{Emotion Regulation: Current Status and Future Prospects}},
url = {http://www.tandfonline.com/doi/abs/10.1080/1047840X.2014.940781},
volume = {26},
year = {2015}
}
@article{Garcia2016,
abstract = {Gathering data about the emotional journey of a product and user experience is on the forefront of both user and customer experience, but the question remains: What is the best way to do this? There are sloughs of solutions that claim to capture the user's emotions in various ways: via biometrics, facial analysis, vocal analysis, and more. While some of these solutions can provide you with seemingly accurate feedback, they can also be intrusive. Other solutions can be expensive, leaving a start up or other lean UX team struggling to find these answers. This case study follows UEGroup's approach to tackle the issues surrounding capturing the emotional experience of a product, with a focus on an agile self-reporting method. In this case study we attempt to answer the question- is self-reporting more or less effective than these other emotion capturing methods?},
author = {Garcia, Sarah E. and Hammond, Laura M.},
doi = {10.1145/2851581.2851605},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Garcia, Hammond - 2016 - Capturing {\&}amp Measuring Emotions in UX.pdf:pdf},
isbn = {9781450340823},
journal = {Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems - CHI EA '16},
pages = {777--785},
title = {{Capturing {\&} Measuring Emotions in UX}},
url = {http://dl.acm.org/citation.cfm?doid=2851581.2851605},
year = {2016}
}
@article{Tigwell2016,
abstract = {Emoji provide a way to express nonverbal conversational cues in computer-mediated communication. However, people need to share the same understanding of what each emoji symbolises, otherwise communication can breakdown. We surveyed 436 people about their use of emoji and ran an interactive study using a two-dimensional emotion space to investigate (1) the variation in people's interpretation of emoji and (2) their interpretation of corre- sponding Android and iOS emoji. Our results show vari- ations between people's ratings within and across plat- forms. We outline our solution to reduce misunderstand- ings that arise from different interpretations of emoji.},
author = {Tigwell, Garreth W and Flatla, David R.},
doi = {2957265.2961844},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Tigwell, Flatla - 2016 - “ Oh that ' s what you meant !” Reducing Emoji Misunderstanding.pdf:pdf},
isbn = {978-1-4503-4413-5},
journal = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct (MobileHCI '16)},
keywords = {Computer-Mediated Communication,Emoji,Emotion},
number = {Cmc},
pages = {859--866},
title = {{“ Oh that ' s what you meant !”: Reducing Emoji Misunderstanding}},
url = {http://dl.acm.org/citation.cfm?id=2961844},
year = {2016}
}
@article{Stone2017,
archivePrefix = {arXiv},
arxivId = {10.1145/3025453.302604},
author = {Stone, Maureen},
doi = {10.1145/3025453.3026041},
eprint = {3025453.302604},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Stone - 2017 - Affective Color in Visualization.pdf:pdf},
isbn = {9781450346559},
pages = {1364--1374},
primaryClass = {10.1145},
title = {{Affective Color in Visualization}},
year = {2017}
}
@article{Ruiz2016,
abstract = {The adequate emotional state of students has proved to be essential for favoring learning. This paper explores the possibility of obtaining students' feedback about the emotions they feel in class in order to discover potential emotion patterns that might indicate learning fails. This paper presents a visual dashboard that allows students to track their emotions and follow up on their evolution during the course. We have compiled the principal classroom related emotions and developed a two-phase inquiry process to: verify the possibility to measure students' emotions in classroom; discover how emotions can be displayed to promote self-reflection; and confirm the impact of emotions on learning performance. Our results suggest that students' emotions in class are related to evaluation marks. This shows that early information about students' emotions can be useful for teachers and students to improve classroom results and learning outcomes.},
author = {Ruiz, Samara and Charleer, Sven and Fern{\'{a}}ndez-castro, Isabel and Duval, Erik},
doi = {10.1145/2883851.2883888},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Ruiz et al. - 2016 - Supporting learning by considering emotions Tracking and Visualization . A case study.pdf:pdf},
isbn = {9781450341905},
journal = {LAK '16 6th International Conference on Learning Analytics and Knowledge, April 25 - 29, 2016},
pages = {254--263},
title = {{Supporting learning by considering emotions : Tracking and Visualization . A case study}},
year = {2016}
}
@article{Huisman2013,
abstract = {Abstract In this paper the development process and validation of the LEMtool (Layered Emotion Measurement tool) are described. The LEMtool consists of eight images that display a cartoon figure expressing four positive and four negative emotions using facial ... $\backslash$n},
author = {Huisman, Gijs and van Hout, Marco and Dijk, Ev and van der Geest, Thea and Heylen, Dirk and van Dijk, Elisabeth and van der Geest, Thea and Heylen, Dirk},
doi = {10.1145/2470654.2470706},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Huisman et al. - 2013 - LEMtool Measuring Emotions in Visual Interfaces.pdf:pdf},
isbn = {978-1-4503-1899-0},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
keywords = {emotion,lemtool,user experience,visual appeal,web pages.},
pages = {351--360},
title = {{LEMtool: Measuring Emotions in Visual Interfaces}},
url = {http://doi.acm.org/10.1145/2470654.2470706{\%}5Cnhttp://dl.acm.org/citation.cfm?id=2470706{\%}5Cnfile:///Users/grahamwilson/Documents/Papers/2013/Huisman/Huisman 2013 Proceedings of CHI 2013{\%}5Cn.pdf{\%}5Cnpapers://c80d98e4-9a96-4487-8d06-8e1acc780d86/Paper/p9544},
year = {2013}
}
@article{Pascal2017,
abstract = {Learners' emotional state has proven to be a key factor for successful learning. Visualizing learners' emotions during synchronous on-line learning activities can help tutors in creating and maintaining socio-affective relationships with their learners. However, few dashboards offer emotional information on the learning activity. The current study focuses on synchronous interactions via a videoconferencing tool dedicated to foreign language training. We collected data on learners' emotions in real conditions during ten sessions (five sessions for two learners). We propose to adopt and combine different models of emotions (discrete and dimensional) and to use heterogeneous APIs for measuring learners' emotions from different data sources (audio, video, self-reporting and interaction traces). Based on a thorough data analysis, we propose an approach to combine different cues to infer information on learners' emotional states. We finally present the EMODA dashboard, an affective multimodal and contextual visual analytics dashboard, which allows the tutor to monitor learners' emotions and better understand their evolution during the synchronous learning activity.},
author = {Pascal, Universit{\'{e}} Blaise and Cs, Bohr and Lyon, I A E and Jean, Universit{\'{e}} and Lyon, Moulin and Thomas, Albert},
doi = {10.1145/3027385.3027434},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Pascal et al. - 2017 - EMODA a Tutor Oriented Multimodal and Contextual Emotional Dashboard.pdf:pdf},
isbn = {9781450348706},
keywords = {dashboard,emotions,interactive visualizations,language training,learner monitoring,multimodal data,tutor},
title = {{EMODA : a Tutor Oriented Multimodal and Contextual Emotional Dashboard}},
year = {2017}
}
@article{Winne2006,
abstract = {We assume learners mediate instruction and self-regulate learning. To gather fine-grained time-sequenced data that trace these processes, the Learning Kit Project is developing software, called gStudy. Using cog- nitive tools in gStudy, learners can make notes, create glossaries, label and index content, construct concept maps, search for information, chat and collaborate, and receive coaching. Each of gStudy's tools is designed on the basis of prior research to scaffold learning and help learners enhance self-regulated learning as they investigate study tactics and learning strategies. We describe the software's features and survey some of its foundations in research.},
author = {Winne, P.H. and Nesbit, J.C. and Kumar, V. and a.F. Hadwin and Lajoie, S.P. and Azevedo, R. and Perry, N.E.},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Winne et al. - 2006 - Supporting self-regulated learning with gStudy software The Learning Kit Project.pdf:pdf},
isbn = {1540-0182},
issn = {1540-0182},
journal = {Technology Instruction Cognition and Learning},
keywords = {Self-regulated learning,coaching,collaboration,learning technologies,trace data.},
number = {1/2},
pages = {105},
title = {{Supporting self-regulated learning with gStudy software: The Learning Kit Project}},
url = {http://azevedolab.autotutor.org/files/publications/Winne et al (2006) TICL.pdf},
volume = {3},
year = {2006}
}
@article{Schutz2007,
abstract = {Emotions in Education brings together the work of scholars from around the world and from a variety of disciplines, including emotion psychology, educational psychology, and teacher education. The final section of Emotions in Education calls for an increase in interdisciplinary collaboration among the fields of education, psychology, neuroscience, sociology, economics, cultural anthropology, history, and philosophy so that concepts and methods from these disciplines may be integrated into the study of emotions in education.},
author = {Schutz, P a and Pekrun, Reinhard},
doi = {10.1207/S15326985EP3702},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Schutz, Pekrun - 2007 - Emotions in Education.pdf:pdf},
isbn = {10451595},
issn = {10451595},
journal = {Adult Learning},
number = {2},
pages = {19},
pmid = {7656},
title = {{Emotions in Education}},
volume = {18},
year = {2007}
}
@article{Parnell2011,
abstract = {Flexibility is a key aspiration of contemporary government guidance on school design. Used liberally, the term provides a convenient site for the meeting of educational approach (think flexible, personalised learning, timetabling, groupings) and spatial design (non-bounded, open space, moveable elements, independent structure and services). However, this meeting seems to pose a challenge. As Building Bulletin 95 puts it: '{\ldots}the most flexibly designed spaces can only work if building users have a flexible attitude.' Framing flexibility in the discourse of autonomy, this paper contends that it can be understood as a 'tool' to enable children to experience authorship of their own learning. The paper draws on participatory action research with primary and secondary schools in England in which the built environment and placemaking were explored as a means to support learning. Through examples, it is argued that once children are enabled to experience their learning environment as 'flexible', by changing it themselves, they are better able to self-direct their learning. Findings show that flexible learning space is encouraged when children and teachers experience together how their environment can support their learning needs. Once established, it is an environment that is constantly changing according to the needs of individuals and groups. The paper concludes that flexibility, at the congruence of spatial design and learning, can only be attained once children feel trusted to shape their environment within an enabling school culture. [ABSTRACT FROM AUTHOR] Copyright of Educational {\&} Child Psychology is the property of British Psychological Society and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
author = {Parnell, Rosie and Procter, Lisa},
doi = {10.1002/ace},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Parnell, Procter - 2011 - Flexibility and placemaking for autonomy in learning.pdf:pdf},
isbn = {02671611},
issn = {02671611},
journal = {Educational and Child Psychology},
keywords = {Autonomy,Flexibility,Pedagogy,Personalised learning,Placemaking,School design},
number = {1},
pages = {77--88},
pmid = {59574397},
title = {{Flexibility and placemaking for autonomy in learning}},
volume = {28},
year = {2011}
}
@article{Goetz2010,
abstract = {The focus of this study is on everyday positive emotions and their relations to critical appraisal anteced- ents. Following from classical appraisal theory and Pek- run's (2006) control-value theory of achievement emotions, two research questions were addressed, namely whether cognitive appraisals of control and value were related to discrete positive emotions in everyday situations and whe- ther control and value antecedents interact in predicting these emotions. We further investigated whether control/ value and positive emotion relations changed as a function of situational factors (achievement vs. non-achievement settings). 50 university freshmen (78{\%} female) were assessed by use of the experience sampling method for a period of 1 week, with intraindividual analyses conducted using a multilevel, idiographic approach. Consistent with our hypotheses, the emotions of enjoyment, pride, and contentment were positively related to control and value appraisals. Further, control and value interacted to predict these positive emotions. The strength of appraisal/positive emotion relations was equivalent across achievement vs. non-achievement settings. Implications for future research are discussed.},
author = {Goetz, Thomas and Frenzel, Anne C. and Stoeger, Heidrun and Hall, Nathan C.},
doi = {10.1007/s11031-009-9152-2},
file = {:Users/nasun/Library/Application Support/Mendeley Desktop/Downloaded/Goetz et al. - 2010 - Antecedents of everyday positive emotions An experience sampling analysis.pdf:pdf},
isbn = {0146-7239},
issn = {01467239},
journal = {Motivation and Emotion},
keywords = {Appraisal,Contentment,Control,Emotion,Enjoyment,Experience sampling method,Pride,Value},
number = {1},
pages = {49--62},
title = {{Antecedents of everyday positive emotions: An experience sampling analysis}},
volume = {34},
year = {2010}
}
@article{Jacobs1974,
author = {Jacobs, Alfred},
journal = {The group as agent of change},
mendeley-groups = {Lyon{\_}Emotions},
pages = {408--448},
publisher = {Behavioral Publications New York},
title = {{The use of feedback in groups}},
year = {1974}
}
@book{Falchikov2013,
author = {Falchikov, Nancy},
isbn = {1134395752},
mendeley-groups = {Lyon{\_}Emotions},
publisher = {Routledge},
title = {{Improving assessment through student involvement: Practical solutions for aiding learning in higher and further education}},
year = {2013}
}
@article{Race1996,
author = {Race, Phil},
issn = {0964-6353},
journal = {NEW ACADEMIC-BIRMINGHAM-},
mendeley-groups = {Lyon{\_}Emotions},
pages = {3--6},
publisher = {SEDA},
title = {{The art of assessing 2}},
volume = {5},
year = {1996}
}
@article{Lave1998,
author = {Lave, Jean and Wenger, Etienne},
journal = {Retrieved June},
mendeley-groups = {Lyon{\_}Emotions},
pages = {2008},
title = {{Communities of practice}},
volume = {9},
year = {1998}
}
